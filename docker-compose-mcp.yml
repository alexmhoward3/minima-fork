version: '3.9'
services:

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    ports:
      - 6333:6333
      - 6334:6334
    expose:
      - 6333
      - 6334
      - 6335
    volumes:
      - F:/qdrant_data:/qdrant/storage
    environment:
      QDRANT__LOG_LEVEL: "INFO"

  mcp_server:
    build: 
      context: ./mcp-server
      dockerfile: Dockerfile
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - ${LOCAL_FILES_PATH}:/usr/src/app/local_files/
      - huggingface_cache:/root/.cache/huggingface      
    environment:
      - PYTHONPATH=/usr/src/app
      - PYTHONUNBUFFERED=1
      # Model settings
      - EMBEDDING_MODEL_ID=${EMBEDDING_MODEL_ID}
      - EMBEDDING_SIZE=${EMBEDDING_SIZE}
      - RERANKER_MODEL=${RERANKER_MODEL}
      - DEVICE=cuda
      # Processing settings
      - CHUNK_SIZE=${CHUNK_SIZE}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP}
      - CHUNK_STRATEGY=h2
      # Path settings
      - LOCAL_FILES_PATH=${LOCAL_FILES_PATH}
      - CONTAINER_PATH=/usr/src/app/local_files/
      # Logging
      - LOG_LEVEL=INFO
      - LOG_FILE=/var/log/minima.log
    depends_on:
      - qdrant
volumes:
  huggingface_cache:
